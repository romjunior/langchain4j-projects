
#LLM
quarkus.langchain4j.ollama.chat-model.model-name=llama3.1
quarkus.langchain4j.ollama.log-requests=true
quarkus.langchain4j.ollama.log-responses=true
quarkus.langchain4j.ollama.chat-model.temperature=0.1
quarkus.langchain4j.ollama.chat-model.top-p=0.5
quarkus.langchain4j.ollama.chat-model.top-k=40
quarkus.langchain4j.guardrails.max-retries=2

#Redis
quarkus.redis.hosts=redis://localhost:6379
parkinglot.memoryTime=30
parkinglot.messagesQuantity=30